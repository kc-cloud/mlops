{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Secure MLOps Pipeline for LLM Fine-Tuning\n",
    "\n",
    "This notebook demonstrates a complete secure MLOps pipeline with:\n",
    "- Secure model download from HuggingFace\n",
    "- Container security with ECR vulnerability scanning\n",
    "- SageMaker training with security controls\n",
    "- Experiment tracking\n",
    "- Performance threshold validation\n",
    "- Model registry and versioning\n",
    "- Secure endpoint deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.experiments.run import Run\n",
    "import yaml\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Import custom modules\n",
    "from src.model_management.secure_model_downloader import SecureModelDownloader\n",
    "from src.security.ecr_manager import SecureECRManager\n",
    "from src.deployment.model_registry import SecureModelRegistry\n",
    "from src.deployment.deploy import SecureEndpointDeployer\n",
    "\n",
    "print('✓ All imports successful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "session = sagemaker.Session()\n",
    "region = session.boto_region_name\n",
    "role = get_execution_role()  # Or specify your role ARN\n",
    "bucket = session.default_bucket()\n",
    "\n",
    "# Load configurations\n",
    "with open('../config/training_config.yaml', 'r') as f:\n",
    "    training_config = yaml.safe_load(f)\n",
    "\n",
    "with open('../config/security_config.yaml', 'r') as f:\n",
    "    security_config = yaml.safe_load(f)\n",
    "\n",
    "print(f'Region: {region}')\n",
    "print(f'Role: {role}')\n",
    "print(f'Bucket: {bucket}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Securely Download Model from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set HuggingFace token (stored in AWS Secrets Manager)\n",
    "# Alternatively, set environment variable: os.environ['HUGGINGFACE_TOKEN'] = 'your_token'\n",
    "\n",
    "downloader = SecureModelDownloader()\n",
    "\n",
    "# Download model with security controls\n",
    "model_path = downloader.download_model(\n",
    "    model_id='gpt2',  # Use a smaller model for demo\n",
    "    local_dir='./models/base-model',\n",
    "    cache_dir='./cache'\n",
    ")\n",
    "\n",
    "print(f'✓ Model downloaded to: {model_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload model to S3 with encryption\n",
    "s3_model_path = f's3://{bucket}/models/base-model/'\n",
    "\n",
    "downloader.upload_to_s3(\n",
    "    local_path=model_path,\n",
    "    s3_uri=s3_model_path,\n",
    "    encrypt=True\n",
    ")\n",
    "\n",
    "print(f'✓ Model uploaded to: {s3_model_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Build and Push Secure Container to ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create secure ECR repository\n",
    "ecr_manager = SecureECRManager(region=region)\n",
    "\n",
    "repository_name = 'secure-mlops-training'\n",
    "repo = ecr_manager.create_secure_repository(\n",
    "    repository_name=repository_name,\n",
    "    scan_on_push=True,\n",
    "    enable_encryption=True\n",
    ")\n",
    "\n",
    "print(f\"✓ Repository created: {repo['repositoryUri']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and push image with vulnerability scanning\n",
    "# Using the shell script for better control\n",
    "!cd .. && bash scripts/build_and_push.sh {repository_name} v1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the image URI\n",
    "with open('../.ecr_image_uri', 'r') as f:\n",
    "    image_uri = f.read().strip()\n",
    "\n",
    "print(f'Training image URI: {image_uri}')\n",
    "\n",
    "# Check scan results\n",
    "scan_results = ecr_manager.get_scan_results(repository_name, 'v1.0')\n",
    "if scan_results:\n",
    "    print('\\nVulnerability Scan Results:')\n",
    "    print(json.dumps(scan_results.get('findingSeverityCounts', {}), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this demo, we'll use a sample dataset\n",
    "# In production, you would upload your own data to S3\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load sample dataset\n",
    "dataset = load_dataset('wikitext', 'wikitext-2-raw-v1', split='train[:1000]')\n",
    "eval_dataset = load_dataset('wikitext', 'wikitext-2-raw-v1', split='validation[:100]')\n",
    "\n",
    "# Save to disk\n",
    "dataset.save_to_disk('./data/train')\n",
    "eval_dataset.save_to_disk('./data/validation')\n",
    "\n",
    "print(f'✓ Training samples: {len(dataset)}')\n",
    "print(f'✓ Validation samples: {len(eval_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload data to S3 with encryption\n",
    "import subprocess\n",
    "\n",
    "s3_train_path = f's3://{bucket}/data/train/'\n",
    "s3_eval_path = f's3://{bucket}/data/validation/'\n",
    "\n",
    "subprocess.run([\n",
    "    'aws', 's3', 'sync', './data/train/', s3_train_path,\n",
    "    '--sse', 'aws:kms'\n",
    "])\n",
    "\n",
    "subprocess.run([\n",
    "    'aws', 's3', 'sync', './data/validation/', s3_eval_path,\n",
    "    '--sse', 'aws:kms'\n",
    "])\n",
    "\n",
    "print(f'✓ Data uploaded to S3')\n",
    "print(f'  Train: {s3_train_path}')\n",
    "print(f'  Eval: {s3_eval_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Run Secure Training Job with Experiment Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create experiment\n",
    "experiment_name = 'secure-llm-finetuning'\n",
    "run_name = f'trial-{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}'\n",
    "\n",
    "# Training hyperparameters\n",
    "hyperparameters = {\n",
    "    'model_name': 'gpt2',\n",
    "    'epochs': 1,  # Reduced for demo\n",
    "    'batch_size': 4,\n",
    "    'learning_rate': 2e-5,\n",
    "    'max_seq_length': 512,\n",
    "    'lora_r': 16,\n",
    "    'lora_alpha': 32,\n",
    "    'train_data': '/opt/ml/input/data/train',\n",
    "    'eval_data': '/opt/ml/input/data/validation',\n",
    "    'max_perplexity': 20.0,\n",
    "    'max_eval_loss': 1.5,\n",
    "    'experiment_name': experiment_name,\n",
    "    'run_name': run_name\n",
    "}\n",
    "\n",
    "print('Hyperparameters:')\n",
    "print(json.dumps(hyperparameters, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SageMaker Estimator with security settings\n",
    "estimator = Estimator(\n",
    "    image_uri=image_uri,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.g5.xlarge',\n",
    "    output_path=f's3://{bucket}/models/output/',\n",
    "    hyperparameters=hyperparameters,\n",
    "    use_spot_instances=True,\n",
    "    max_run=3600,\n",
    "    max_wait=7200,\n",
    "    \n",
    "    # Security settings\n",
    "    encrypt_inter_container_traffic=True,\n",
    "    # Uncomment if using VPC:\n",
    "    # subnets=security_config['security']['vpc']['subnets'],\n",
    "    # security_group_ids=security_config['security']['vpc']['security_group_ids'],\n",
    "    \n",
    "    # Encryption\n",
    "    volume_kms_key=security_config['security']['encryption'].get('volume_kms_key_id'),\n",
    "    output_kms_key=security_config['security']['encryption'].get('s3_kms_key_id'),\n",
    "    \n",
    "    # Experiment tracking\n",
    "    sagemaker_session=session,\n",
    "    tags=[\n",
    "        {'Key': 'Project', 'Value': 'SecureMLOps'},\n",
    "        {'Key': 'Environment', 'Value': 'Development'}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print('✓ Estimator configured')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training job\n",
    "with Run(\n",
    "    experiment_name=experiment_name,\n",
    "    run_name=run_name,\n",
    "    sagemaker_session=session\n",
    ") as run:\n",
    "    estimator.fit({\n",
    "        'train': s3_train_path,\n",
    "        'validation': s3_eval_path\n",
    "    }, wait=True)\n",
    "    \n",
    "print('✓ Training completed')\n",
    "print(f'Model artifacts: {estimator.model_data}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Evaluate Model and Check Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download model artifacts for evaluation\n",
    "import subprocess\n",
    "import tarfile\n",
    "\n",
    "# Download model.tar.gz\n",
    "model_data = estimator.model_data\n",
    "subprocess.run(['aws', 's3', 'cp', model_data, './model.tar.gz'])\n",
    "\n",
    "# Extract\n",
    "with tarfile.open('./model.tar.gz', 'r:gz') as tar:\n",
    "    tar.extractall('./trained_model')\n",
    "\n",
    "print('✓ Model artifacts downloaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "from src.training.evaluator import ModelEvaluator\n",
    "\n",
    "evaluator = ModelEvaluator('./trained_model')\n",
    "\n",
    "# Load eval dataset\n",
    "from datasets import load_from_disk\n",
    "eval_dataset = load_from_disk('./data/validation')\n",
    "\n",
    "# Run evaluation\n",
    "metrics = evaluator.evaluate_metrics(eval_dataset)\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('EVALUATION METRICS')\n",
    "print('='*60)\n",
    "for key, value in metrics.items():\n",
    "    print(f'{key}: {value}')\n",
    "print('='*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check performance thresholds\n",
    "thresholds = {\n",
    "    'perplexity_max': 20.0,\n",
    "    'eval_loss_max': 1.5\n",
    "}\n",
    "\n",
    "passed, failures = evaluator.check_thresholds(metrics, thresholds)\n",
    "\n",
    "if passed:\n",
    "    print('\\n✓ Model PASSED all performance thresholds')\n",
    "    approval_status = 'PendingManualApproval'\n",
    "else:\n",
    "    print('\\n✗ Model FAILED performance thresholds')\n",
    "    for failure in failures:\n",
    "        print(f'  - {failure}')\n",
    "    approval_status = 'Rejected'\n",
    "    raise ValueError('Model does not meet performance requirements')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Register Model in Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model registry\n",
    "registry = SecureModelRegistry(region=region)\n",
    "\n",
    "# Create model package group\n",
    "model_package_group_name = 'secure-llm-models'\n",
    "registry.create_model_package_group(\n",
    "    group_name=model_package_group_name,\n",
    "    description='Secure LLM models with performance validation'\n",
    ")\n",
    "\n",
    "print(f'✓ Model package group: {model_package_group_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register model version\n",
    "model_package_arn = registry.register_model(\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    model_data_url=estimator.model_data,\n",
    "    image_uri=image_uri,\n",
    "    model_metrics=metrics,\n",
    "    approval_status=approval_status\n",
    ")\n",
    "\n",
    "print(f'✓ Model registered: {model_package_arn}')\n",
    "print(f'  Approval status: {approval_status}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Review and Approve Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all model versions\n",
    "versions = registry.list_model_versions(model_package_group_name)\n",
    "\n",
    "print('Model Versions:')\n",
    "for v in versions:\n",
    "    print(f\"  Version {v.get('version', 'N/A')}: {v['status']} (created {v['created']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approve model (manual step - in production this would be done by ML team)\n",
    "# Only approve if metrics look good\n",
    "\n",
    "if passed:\n",
    "    registry.update_approval_status(\n",
    "        model_package_arn=model_package_arn,\n",
    "        approval_status='Approved',\n",
    "        approval_description=f'Model approved with perplexity={metrics[\"perplexity\"]:.2f}'\n",
    "    )\n",
    "    print('✓ Model approved for deployment')\n",
    "else:\n",
    "    print('✗ Model not approved - does not meet performance thresholds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Deploy to SageMaker Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize deployer\n",
    "deployer = SecureEndpointDeployer(\n",
    "    security_config_path='../config/security_config.yaml',\n",
    "    region=region\n",
    ")\n",
    "\n",
    "# Deploy endpoint\n",
    "endpoint_name = 'secure-llm-endpoint'\n",
    "\n",
    "endpoint_arn = deployer.deploy_model(\n",
    "    model_package_arn=model_package_arn,\n",
    "    endpoint_name=endpoint_name,\n",
    "    instance_type='ml.g5.xlarge',\n",
    "    instance_count=1,\n",
    "    enable_monitoring=True,\n",
    "    enable_autoscaling=True,\n",
    "    tags=[\n",
    "        {'Key': 'Project', 'Value': 'SecureMLOps'},\n",
    "        {'Key': 'Environment', 'Value': 'Production'}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f'✓ Endpoint deployed: {endpoint_arn}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Test Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the endpoint\n",
    "test_payload = json.dumps({\n",
    "    'inputs': 'Once upon a time',\n",
    "    'parameters': {\n",
    "        'max_new_tokens': 50,\n",
    "        'temperature': 0.7\n",
    "    }\n",
    "})\n",
    "\n",
    "result = deployer.invoke_endpoint(\n",
    "    endpoint_name=endpoint_name,\n",
    "    payload=test_payload,\n",
    "    content_type='application/json'\n",
    ")\n",
    "\n",
    "print('\\nEndpoint Response:')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Security Controls Implemented:\n",
    "\n",
    "1. **Model Download Security**\n",
    "   - Token-based authentication with HuggingFace\n",
    "   - Credentials stored in AWS Secrets Manager\n",
    "   - Model integrity verification\n",
    "   - Audit logging\n",
    "\n",
    "2. **Container Security**\n",
    "   - ECR vulnerability scanning (basic + enhanced)\n",
    "   - Immutable image tags\n",
    "   - KMS encryption at rest\n",
    "   - Non-root container execution\n",
    "\n",
    "3. **Training Security**\n",
    "   - VPC isolation (optional)\n",
    "   - Encrypted inter-container traffic\n",
    "   - KMS encryption for volumes and output\n",
    "   - IAM least-privilege roles\n",
    "\n",
    "4. **Model Governance**\n",
    "   - Performance threshold validation\n",
    "   - Model versioning in registry\n",
    "   - Approval workflow\n",
    "   - Experiment tracking\n",
    "\n",
    "5. **Deployment Security**\n",
    "   - VPC endpoint deployment (optional)\n",
    "   - Data capture for monitoring\n",
    "   - Auto-scaling\n",
    "   - Encryption at rest and in transit\n",
    "\n",
    "### Compliance Features:\n",
    "- Complete audit trail in CloudWatch Logs\n",
    "- Model lineage tracking\n",
    "- Automated quality gates\n",
    "- Regular vulnerability scanning\n",
    "- Data encryption throughout pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to delete endpoint and associated resources\n",
    "# deployer.delete_endpoint(\n",
    "#     endpoint_name=endpoint_name,\n",
    "#     delete_config=True,\n",
    "#     delete_model=True\n",
    "# )\n",
    "# print('✓ Endpoint deleted')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
